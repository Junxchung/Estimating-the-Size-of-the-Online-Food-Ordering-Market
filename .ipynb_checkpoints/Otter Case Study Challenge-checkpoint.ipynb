{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE A BETTER NAME THAN THIS Otter Case Study Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = pd.read_csv('css_public_all_ofos_locations.csv', \n",
    "                   sep = chr(1), \n",
    "                   low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>name</th>\n",
       "      <th>platform</th>\n",
       "      <th>sub_platform</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>active</th>\n",
       "      <th>standardized_name</th>\n",
       "      <th>restaurant_chain</th>\n",
       "      <th>delivery_radius</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9744</td>\n",
       "      <td>Loco Coco</td>\n",
       "      <td>caviar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.765004</td>\n",
       "      <td>-73.965961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>TRUE</td>\n",
       "      <td>loco_coco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4903</td>\n",
       "      <td>Musubi</td>\n",
       "      <td>caviar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.504641</td>\n",
       "      <td>-122.643806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>musubi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4723</td>\n",
       "      <td>The Bakers' Lounge</td>\n",
       "      <td>caviar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.924559</td>\n",
       "      <td>-76.990115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>the_bakers_lounge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  restaurant_id                name platform sub_platform   latitude  \\\n",
       "0          9744           Loco Coco   caviar          NaN  40.765004   \n",
       "1          4903              Musubi   caviar          NaN  45.504641   \n",
       "2          4723  The Bakers' Lounge   caviar          NaN  38.924559   \n",
       "\n",
       "     longitude city country active  standardized_name restaurant_chain  \\\n",
       "0   -73.965961  NaN      US   TRUE          loco_coco              NaN   \n",
       "1  -122.643806  NaN      US  FALSE             musubi              NaN   \n",
       "2   -76.990115  NaN      US  FALSE  the_bakers_lounge              NaN   \n",
       "\n",
       "  delivery_radius  geom  \n",
       "0             NaN   NaN  \n",
       "1             NaN   NaN  \n",
       "2             NaN   NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 644089 entries, 0 to 644088\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   restaurant_id      644089 non-null  object \n",
      " 1   name               644086 non-null  object \n",
      " 2   platform           644087 non-null  object \n",
      " 3   sub_platform       599311 non-null  object \n",
      " 4   latitude           644086 non-null  object \n",
      " 5   longitude          644070 non-null  object \n",
      " 6   city               56196 non-null   object \n",
      " 7   country            644071 non-null  object \n",
      " 8   active             643867 non-null  object \n",
      " 9   standardized_name  643872 non-null  object \n",
      " 10  restaurant_chain   169 non-null     object \n",
      " 11  delivery_radius    354661 non-null  object \n",
      " 12  geom               0 non-null       float64\n",
      "dtypes: float64(1), object(12)\n",
      "memory usage: 63.9+ MB\n"
     ]
    }
   ],
   "source": [
    "original_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided data has 644089 rows and 13 columns of restaurant data\n"
     ]
    }
   ],
   "source": [
    "print('The provided data has {0} rows and {1} columns of restaurant data.'.format(\n",
    "    original_dataset.shape[0], \n",
    "    original_dataset.shape[1])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PSEUDOCODE \n",
    "\n",
    "# are there some visualizations i can include here?\n",
    "# don't make visualizations needlessly, doesn't make sense unless it's actually useful\n",
    "\n",
    "# AT THE END OF THE PROJECT WHAT IF I USED BASEMAP TO MAP THE BEFORE AND AFTER\n",
    "# AND I CAN ALSO JUST CREATE A MAP WHERE ALL THE DATA POINTS ACTUALLY EXIST ON\n",
    "# THINK MORE ABOUT THIS, THERE'S ROOM FOR SOMETHING REALLY VALUABLE WITH GRAPHING ACTUAL GEOLOGICAL POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PSEUDOCODE \n",
    "\n",
    "# DONE    look up the ones with missing name and fill it in, simple \n",
    "# DONE    for those missing lat \n",
    "# or long values, which isn't a lot, just research and fill it in\n",
    "# do the same with country values, although a glance at those values might reveal most of them, if not all, are US so it won't matter for a model anyways\n",
    "# take an individual look at those that are lableled chains and explore these a little\n",
    "\n",
    "# secondary priorities are to look more deeply at sub platform and delivery radius\n",
    "\n",
    "\n",
    "# AT THE END OF THIS PROJECT I WANT TO IMPLEMENT A ML ALGO ON A CLEAN DATASET AND THEN COMPARE IT TO THE 'CORRECT' VALUE THAT I DETERMINE WITH SIMPLE LABELING FROM LAT AND LONG DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to keep the original provided dataset unaltered\n",
    "# I am making a copy of the data to use for data cleaning, pre-processing, etc\n",
    "\n",
    "data = original_dataset.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to check to see if I can manually insert the missing names of the 3 rows missing values in the 'name' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    restaurant_id name      platform sub_platform latitude  \\\n",
      "34794                        None  NaN  delivery.com          NaN      NaN   \n",
      "236516  Recreation & Wellness Ctr  NaN           NaN          NaN      NaN   \n",
      "316021                  Suite 112  NaN           NaN          NaN      NaN   \n",
      "\n",
      "       longitude city country active standardized_name restaurant_chain  \\\n",
      "34794        NaN  NaN      US  FALSE               NaN              NaN   \n",
      "236516       NaN  NaN     NaN    NaN               NaN              NaN   \n",
      "316021       NaN  NaN     NaN    NaN               NaN              NaN   \n",
      "\n",
      "       delivery_radius  geom  \n",
      "34794              NaN   NaN  \n",
      "236516             NaN   NaN  \n",
      "316021             NaN   NaN  \n"
     ]
    }
   ],
   "source": [
    "# using simple boolean indexing to examine the rows with missing values for the 'name' column\n",
    "\n",
    "print(data[data['name'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deleting Rows with Little to No Value\n",
    "\n",
    "Because there is almost no other data I can use, such as latitude and longitude data, to determine what these restaurants may be, I am deleting these rows of data entirely from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset = ['name'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset now has 644086 rows and 13 columns of restaurant data\n"
     ]
    }
   ],
   "source": [
    "print('The dataset now has {0} rows and {1} columns of restaurant data.'.format(\n",
    "    data.shape[0], \n",
    "    data.shape[1])\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling in Missing Latitude and Longitude Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [restaurant_id, name, platform, sub_platform, latitude, longitude, city, country, active, standardized_name, restaurant_chain, delivery_radius, geom]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# checking what missing values may exist in the latitude column\n",
    "# using simple boolean indexing to examine the rows with missing values for the 'latitude' column\n",
    "\n",
    "print(data[data['latitude'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that getting rid of the rows where the value in the 'name' column was missing also removed the rows that were missing latitude data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only a few of the rows are displayed for easier viewing.\n",
      "\n",
      "--------------------------------------------------------\n",
      "\n",
      "           restaurant_id name  \\\n",
      "344996          Ste 160\"  USD   \n",
      "355635  at Schlotzsky's\"  USD   \n",
      "379703          Ste 160\"  USD   \n",
      "391647            Ste C\"  USD   \n",
      "415762          Ste 100\"  USD   \n",
      "\n",
      "                                                 platform sub_platform  \\\n",
      "344996  [[\"open: 12:00, close: 21:00\"], [\"open: 12:00,...         TRUE   \n",
      "355635  [[\"open: 07:00, close: 20:00\"], [\"open: 07:00,...         TRUE   \n",
      "379703                       [[], [], [], [], [], [], []]        FALSE   \n",
      "391647  [[\"open: 12:00, close: 20:00\"], [\"open: 12:00,...         TRUE   \n",
      "415762  [[\"open: 16:00, close: 20:00\"], [\"open: 12:00,...         TRUE   \n",
      "\n",
      "                      latitude longitude  city country active  \\\n",
      "344996    ohjah_noodle_house_2       NaN  5.99     NaN     40   \n",
      "355635                cinnabon       NaN  5.99     NaN     40   \n",
      "379703             thailicious       NaN  5.99     NaN     45   \n",
      "391647  boss_s_slow_smoked_bbq       NaN  5.99     NaN     45   \n",
      "415762   buon_gusto_ristorante       NaN  5.99     NaN     40   \n",
      "\n",
      "       standardized_name restaurant_chain  delivery_radius  geom  \n",
      "344996               NaN                6     Clark County   NaN  \n",
      "355635               NaN               19  Maricopa County   NaN  \n",
      "379703               NaN               41     Clark County   NaN  \n",
      "391647               NaN               36     Clark County   NaN  \n",
      "415762               NaN                3     Clark County   NaN  \n"
     ]
    }
   ],
   "source": [
    "# using the same method as above to examine the rows with missing values for the 'longitude' column\n",
    "\n",
    "print('Only a few of the rows are displayed for easier viewing.\\n')\n",
    "print('--------------------------------------------------------\\n')\n",
    "print(data[data['longitude'].isnull()][11:])    # remove the indexing to see all rows with missing 'longitude' values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that, for whatever reason, data was not input and/or collected properly for the data points above. The values within each column seem to be in the wrong place. However, I can simply:\n",
    "- Look these restaurants up on the internet\n",
    "- Fill in + replace the existing values with correct values\n",
    "\n",
    "#### Researched Data for Restaurants\n",
    "I'll be looking up the restaurants up by their names, which I am presuming are the values found in the 'latitude' column. I can confirm I am collecting information for the correct restaurants with the other information available (but misplaced) in the other columns.\n",
    "- Row 139276 (Sugarfina) [info](https://www.yelp.com/biz/sugarfina-pasadena-pasadena-2)\n",
    "- Row 187183 (Ohjah Nooodle House) [info](https://www.yelp.com/biz/ohjah-noodle-house-las-vegas-3)\n",
    "- Row 194075 (Novecento Pizzeria) [info](https://www.yelp.com/biz/novecento-pizzeria-las-vegas)\n",
    "- Row 201827 (14th St Cafe Asian Bistro) [info](https://www.yelp.com/biz/14th-st-cafe-asian-bistro-washington-2)\n",
    "- Row 204010 (Straight From Philly Steakout) [info](https://www.yelp.com/biz/straight-from-philly-steakout-henderson-3)\n",
    "- Row 229924 (Tumbao Buns - Downtown Miami) [info](https://www.yelp.com/biz/tumbao-buns-downtown-miami-miami-2)\n",
    "    - The address found on the Yelp page doesn't match with the one provided on the data set. This is most likely due to the fact that this restaurant is technically a food truck, a mobile restuarant that can have different locations. The correct address is listed [here](https://postmates.com/merchant/tumbao-buns-miami)\n",
    "- Row 250287 (Dunkin Donuts) [info](https://www.yelp.com/biz/dunkin-donuts-pompano-beach-7?osq=dunkin+donuts+locations)\n",
    "- Row 294761 (Dos Coyotes Border Cafe) [info](https://www.grubhub.com/restaurant/dos-coyotes-border-cafe-8519-bond-rd-ste-100-elk-grove/1244011)\n",
    "- Row 298940 (China One) [info](https://www.grubhub.com/restaurant/china-one-7080-n-durango-dr-ste-130-las-vegas/394082)\n",
    "- Row 302090 (Fat Boy) [info](https://www.yelp.com/biz/fat-boy-henderson-2)\n",
    "- Row 341279 (Au Bon Pain) [info](https://www.yelp.com/biz/au-bon-pain-chicago-14)\n",
    "- Row 344996 (Ohjah Noodle House 2) [info](https://www.grubhub.com/restaurant/ohjah-noodle-house-35-e-horizon-ridge-pkwy-ste-160-henderson/1121695)\n",
    "    - This may, interestingly, be the same as the other Ohjah Noodle House listed above. Investigate further.\n",
    "- Row 355635 (Cinnabon) [info](https://www.zomato.com/maricopa-county-az/scholtzskys-cinnabon-1-goodyear)\n",
    "- Row 379703 (Thailicious Authentic Thai & Vegan) [info](https://www.yelp.com/biz/thailicious-authentic-thai-and-vegan-henderson?osq=thailicious)\n",
    "- Row 391647 (Boss's Slow Smoked BBQ) [info](https://www.yelp.com/biz/bosss-slow-smoked-bbq-n-las-vegas)\n",
    "- Row 415762 (Buon Gusto Ristorante) [info](https://www.yelp.com/biz/buon-gusto-ristorante-henderson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating My Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['duplicate'] = data.duplicated(subset = ['latitude','longitude'], keep = False) \n",
    "\n",
    "# # keep = False labels everything that was duplicated as True (there's a duplicate of it in the data set)\n",
    "# # creating another column is possible with keep = first if you want to leave the first duplicate labeled as an original just for a simple aggregation\n",
    "\n",
    "# print(data['duplicate'].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
